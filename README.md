# âœ‹ AI Sign Language Detection System  
Real-Time Hand Gesture Recognition using MediaPipe, TensorFlow & TFLite

![Python](https://img.shields.io/badge/Python-3.10-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.12-orange.svg)
![MediaPipe](https://img.shields.io/badge/MediaPipe-Hands-green.svg)
![Flask](https://img.shields.io/badge/Flask-WebApp-lightgrey.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

---

## ğŸ“Œ Overview  
This project is a **real-time Sign Language Detection System** built using:

- âœ… MediaPipe Hands â€“ 21 landmark detection  
- âœ… TensorFlow / Keras â€“ for training gesture classifier  
- âœ… TFLite â€“ for fast mobile/web deployment  
- âœ… Flask Web App â€“ real-time webcam inference  

The system detects custom gestures like **HELLO, HELP, NAME, THANK YOU, BYE, VIKAS**, etc.

---

## âœ¨ Features

âœ… Real-time hand gesture recognition  
âœ… Custom dataset support  
âœ… TFLite optimized model  
âœ… Clean Flask UI with confidence meter  
âœ… Easy-to-train pipeline  
âœ… Multi-class gesture support  
âœ… Works with any Laptop Camera  

---

## ğŸ“‚ Project Structure

```
AIML PROJECT/
â”‚â”€â”€ models/
â”‚   â”œâ”€â”€ convert_to_tflite.py
â”‚   â”œâ”€â”€ label_map.json
â”‚   â”œâ”€â”€ sign_model_best.keras
â”‚   â”œâ”€â”€ sign_model_final.keras
â”‚   â”œâ”€â”€ sign_model_float32.tflite
â”‚   â”œâ”€â”€ sign_model_int8.tflite
â”‚   â””â”€â”€ training_log.csv
â”‚
â”‚â”€â”€ two_hand_dataset/      (Dataset created from collect_data.py)
â”‚â”€â”€ HELLO/
â”‚â”€â”€ HELP/
â”‚â”€â”€ NAME/
â”‚â”€â”€ THANK YOU/
â”‚â”€â”€ BYE/
â”‚
â”‚
â”‚â”€â”€ webapp/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ static/
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html
â”‚
â”‚â”€â”€ src/
â”‚â”€â”€ collect_data.py
â”‚â”€â”€ train_model.py
â”‚â”€â”€ test_hands.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ run.bat
â”‚â”€â”€ README.md
```

---

# âœ… Step-by-Step Guide (Complete Workflow)

This project follows a simple **3-stage AI pipeline**:

---

# 1ï¸âƒ£ Create & Activate Virtual Environment

### âœ… Windows
```bash
python -m venv venv
venv\Scripts\activate
```

### âœ… Linux / Mac
```bash
python3 -m venv venv
source venv/bin/activate
```

---

# 2ï¸âƒ£ Install Required Libraries
Install all dependencies:

```bash
pip install -r requirements.txt
```

---

# 3ï¸âƒ£ Collect Data (Important Step)

Use **collect_data.py** to capture gesture data.

### âœ… Run data collection
```bash
cd src
python collect_data.py
```

### âœ… What happens:
- Webcam opens  
- MediaPipe extracts 21 landmark points  
- Saves landmark vectors into:  

```
two_hand_dataset/<GESTURE_NAME>/
```

### âœ… Example Directory
```
two_hand_dataset/
    HELLO/
    HELP/
    NAME/
    THANK YOU/
    BYE/
```

Press **q** to close the webcam.

---

# 4ï¸âƒ£ Train the Model

Once dataset is ready, train the neural network model:

```bash
cd src
python train_model.py
```

### âœ… Training Output:
Models will be saved in `models/`:

- `sign_model_best.keras`  
- `sign_model_final.keras`  
- Training logs saved to `training_log.csv`  

---

# 5ï¸âƒ£ Convert Model to TFLite (Optional but Recommended)

For fast real-time performance:

```bash
python models/convert_to_tflite.py
```

Outputs:

- `sign_model_float32.tflite`
- `sign_model_int8.tflite`

---

# 6ï¸âƒ£ Run Real-Time Web App

Navigate to the webapp folder:

```bash
cd webapp
python app.py
```

Open your browser:

ğŸ‘‰ http://127.0.0.1:5000/

### âœ… Features of Web App:
- Real-time webcam detection  
- Progress bar (confidence meter)  
- Smooth UI  
- Uses TFLite model for fast performance  

---

# 7ï¸âƒ£ Test Gesture Detection Without Web App

To test with OpenCV only:

```bash
python test_hands.py
```

---

# âœ… Overall Pipeline Summary

| Step | Script | Output |
|------|--------|--------|
| Data Collection | `collect_data.py` | Dataset stored in `two_hand_dataset/` |
| Training | `train_model.py` | `.keras` models saved in `/models/` |
| Convert Model | `convert_to_tflite.py` | `.tflite` models |
| Run Web App | `app.py` | Real-time gesture detection |

---

# ğŸ“¸ Screenshots (Add Yours)

Place your UI and model screenshots in:

```
/screenshots
    â”œâ”€â”€ ui.png
    â”œâ”€â”€ prediction.png
    â”œâ”€â”€ dataset_example.png
    â”œâ”€â”€ training_plot.png
```

You can embed them like:

```markdown
![Web UI](screenshots/ui.png)
```

---

# âœ… Requirements

All required packages are listed in:

```
requirements.txt
```

Includes:

- TensorFlow
- MediaPipe
- OpenCV
- Flask
- NumPy
- Pandas

---

# âœ… License  
This project is licensed under the **MIT License**.

---

# ğŸ™Œ Author  
**Vikas Suthar**  
AIML Student | Deep Learning | Computer Vision  

